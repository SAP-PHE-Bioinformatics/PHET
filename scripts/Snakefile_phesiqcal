#### modify config files with sample sheets ####

configfile: "config.yaml"


### import other jobs ###
import pathlib
import os, getpass, shutil, re, psutil
import pandas

#### target rules ####

rule all:
    input:
        expand("{sample}/yield.tab", sample=config["controls+samples"]),
        expand("{sample}/kraken2.tab", sample=config["controls+samples"]),
        expand("{sample}/kraken_gtdb.tab", sample=config["controls+samples"]),
        directory(expand("{sample}/shovill", sample=config["samples"])),
        expand("filtered_contigs/{sample}.fna", sample=config["samples"]),
        expand("{sample}/kraken2_assembly.tab", sample=config["samples"]),
        "assembled_kraken_species.tab",
        "denovo.tab",
        "mlst.tab",
        expand("{sample}/abricate.tab", sample=config["samples"]),
        "resistome.tab",
        expand("{sample}/vfdb.tab", sample=config["samples"]),
        "virulome.tab",
        expand("{sample}/plasmid.tab", sample=config["samples"]),
        directory(expand("{sample}/prokka", sample=config["samples"])),
        "plasmid.tab",
        directory(expand("{sample}/ARIBA", sample=config["samples"])),
        "seq_data.tab",
        "species_identification.tab",
        "gtdb_species_id.tab",
        "QC_summary.txt",
        "gene_summary.txt",
        "PHET/phet.yaml"


rule fq:
   input:
        r1= "input/{sample}_R1.fastq.gz",
        r2= "input/{sample}_R2.fastq.gz"
   output:
        "{sample}/yield.tab"
   shell:
        "fq {input.r1} {input.r2} > {output}"

rule kraken:
   input:
        r1 = "input/{sample}_R1.fastq.gz",
        r2 = "input/{sample}_R2.fastq.gz"
   output:
        "{sample}/kraken2.tab"
   threads: 4
   shell:
        "kraken2 --threads {threads} --memory-mapping --db /scratch/kraken/k2_pluspf_20220607/ --report {output} --paired {input.r1} {input.r2}"

rule kraken_gtdb:
     input:
          r1 = "input/{sample}_R1.fastq.gz",
          r2 = "input/{sample}_R2.fastq.gz"
     output:
          "{sample}/kraken_gtdb.tab"
     params:
          database="/scratch/kraken/gtdb/"
     threads: 4
     shell:
          "kraken2 --threads {threads} --memory-mapping --db {params.database} --report {output} --paired {input.r1} {input.r2}"
          
rule shovill:
   input:
        r1 = "input/{sample}_R1.fastq.gz",
        r2 = "input/{sample}_R2.fastq.gz"
   output:
        directory("{sample}/shovill")
   threads: 4
   shell:
        "shovill --ram 32 --force --depth 80 --gsize 6M  --cpus {threads} -R1 {input.r1} -R2 {input.r2} --outdir {output}"

rule remove_small:
   input:
        "{sample}/shovill"
   output:
        "filtered_contigs/{sample}.fna"
   shell:
        "seqtk seq -L 500 {input}/contigs.fa > {output}"

rule kraken_on_assemblies:
    input:
         "filtered_contigs/{sample}.fna"
    output:
         "{sample}/kraken2_assembly.tab"
    conda:
         "phesiqcal"
    threads: 4
    shell:
         "kraken2 --threads {threads} --memory-mapping --db /scratch/kraken/k2_pluspf_20220607/ --report {output} {input}"

rule prokka:
   input:
        "filtered_contigs/{sample}.fna"
   output:
        directory("{sample}/prokka")
   params:
        name = '{sample}',
        locus = '{sample}',
        threads = 16
   shell:
        "prokka --cpus {params.threads} --locustag {params.locus} --prefix {params.name} --outdir {output} {input}"

rule assembly_quality:
   input:
        expand("filtered_contigs/{sample}.fna", sample=config["samples"])
   output:
        "denovo.tab"
   shell:
         "fa -e -t {input} > {output}"

rule mlst:
   input:
        expand("filtered_contigs/{sample}.fna", sample=config["samples"])
   output:
        "mlst.tab"
   conda:
        "mlst"
   shell:
        "mlst {input} > {output}"

rule abricate:
   input:
        "filtered_contigs/{sample}.fna"
   output:
        "{sample}/abricate.tab"
   shell:
        "abricate --db card {input} > {output}"

rule abricate_sum:
   input:
        expand("{sample}/abricate.tab", sample=config["samples"])
   output:
        "resistome.tab"
   shell:
        "abricate --summary {input} > {output}"

rule vfdb:
   input:
        "filtered_contigs/{sample}.fna"
   output:
        "{sample}/vfdb.tab"
   shell:
        "abricate --db vfdb {input} > {output}"

rule vfdb_sum:
   input:
        expand("{sample}/vfdb.tab", sample=config["samples"])
   output:
        "virulome.tab"
   shell:
        "abricate --summary {input} > {output}"

rule plasmid:
   input:
        "filtered_contigs/{sample}.fna"
   output:
        "{sample}/plasmid.tab"
   shell:
        "abricate --db plasmidfinder {input} > {output}"

rule plasmid_sum:
   input:
        expand("{sample}/plasmid.tab", sample=config["samples"])
   output:
        "plasmid.tab"
   shell:
        "abricate --summary {input} > {output}"


rule ariba:
    input:
        R1 = "input/{sample}_R1.fastq.gz",
        R2 = "input/{sample}_R2.fastq.gz",
        Ref = "/phe/tools/ariba/database/CARD/out.card_3.2.7.prepareref/"
    output:
        directory("{sample}/ARIBA/")
    conda:
        "seroba"
    shell:
        "ariba run {input.Ref} {input.R1} {input.R2} {output} --threads 4"
        
rule seq_data:
    input:
        expand("{sample}/yield.tab", sample=config["controls+samples"])
    output:
        "seq_data.tab"
    shell:
        "/phe/tools/PHET/scripts/compile_seq_data.sh {input} > {output}"

rule species_id:
   input:
        expand("{sample}/kraken2.tab", sample = config["controls+samples"])
   output:
        "species_identification.tab"
   run:
        import pandas, pathlib, subprocess
        kfiles = f"{input}".split()
        id_table = pandas.DataFrame()
        for k in kfiles:
            kraken = pathlib.Path(k)
            df = pandas.read_csv(kraken, sep = "\t", header =None, names = ['percentage', 'frag1', 'frag2','code','taxon','name'])
            df['percentage'] = df['percentage'].apply(lambda x:float(x.strip('%')) if isinstance(x, str) == True else float(x))
            df = df.sort_values(by = ['percentage'], ascending = False)
            df = df[df['code'].isin(['U','S'])]
            df = df.reset_index(drop = True)
            tempdf = pandas.DataFrame()
            d = {}
            t =  df['name'].count()
            for i in range((t if t < 3 else 3)):
               d.update({'#Accession': f"{kraken.parts[0]}",
                        f"#{i+1} Match": df.loc[i, 'name'].strip(), f"%{i+1}": df.loc[i, 'percentage']
                        })
            tempdf = pandas.DataFrame(data = d, index = [0])
            if id_table.empty:
               id_table = tempdf
            else:
               id_table = id_table.append(tempdf, sort = True)


          #   d = {'#Accession': f"{kraken.parts[0]}",
          #           '#1 Match': df.loc[0,'name'].strip(), '%1': df.loc[0,'percentage'],
          #           '#2 Match': df.loc[1,'name'].strip(), '%2': df.loc[1,'percentage'],
          #           '#3 Match': df.loc[2,'name'].strip(), '%3': df.loc[2,'percentage']
          #        }

          #   tempdf = pandas.DataFrame(data = d, index= [0])
          #   if id_table.empty:
          #           id_table = tempdf
          #   else:
          #           id_table = id_table.append(tempdf, sort = True)
        cols_list = ['#Accession', '#1 Match', '%1', '#2 Match', '%2', '#3 Match', '%3']
        id_table = id_table.reindex(cols_list, axis = 'columns')
        id_table.to_csv(f"{output}", sep = "\t", index = False)
        subprocess.run("sed -i 's/%[0-9]/%/g' {output}", shell=True)


rule species_id_gtdb:
     input:
        expand("{sample}/kraken_gtdb.tab", sample = config["controls+samples"])
     output:
        "gtdb_species_id.tab"
     run:
        import pandas, pathlib, subprocess
        gfiles = f"{input}".split()
        id_table = pandas.DataFrame()
        for k in gfiles:
            kraken = pathlib.Path(k)
            df = pandas.read_csv(kraken, sep = "\t", header =None, names = ['percentage', 'frag1', 'frag2','code','taxon','name'])
            df['percentage'] = df['percentage'].apply(lambda x:float(x.strip('%')) if isinstance(x, str) == True else float(x))
            df = df.sort_values(by = ['percentage'], ascending = False)
            df = df[df['code'].isin(['U','S'])]
            df = df.reset_index(drop = True)
            tempdf = pandas.DataFrame()
            d = {}
            t =  df['name'].count()
            for i in range((t if t < 3 else 3)):
               d.update({'#Accession': f"{kraken.parts[0]}",
                        f"#{i+1} Match": df.loc[i, 'name'].strip(), f"%{i+1}": df.loc[i, 'percentage']
                        })
            tempdf = pandas.DataFrame(data = d, index = [0])
            if id_table.empty:
               id_table = tempdf
            else:
               id_table = id_table.append(tempdf, sort = True)

        cols_list = ['#Accession', '#1 Match', '%1', '#2 Match', '%2', '#3 Match', '%3']
        id_table = id_table.reindex(cols_list, axis = 'columns')
        id_table.to_csv(f"{output}", sep = "\t", index = False)
        subprocess.run("sed -i 's/%[0-9]/%/g' {output}", shell=True)


rule kraken_assembly_sum:
     input:
          expand("{sample}/kraken2_assembly.tab", sample = config["samples"])
     output:
          "assembled_kraken_species.tab"
     run:
          import pandas, pathlib, subprocess
          afiles = f"{input}".split()
          id_table = pandas.DataFrame()
          for a in afiles:
               kraken_a = pathlib.Path(a)
               df = pandas.read_csv(kraken_a, sep = "\t", header = None, names = ['percentage', 'frag1', 'frag2',
               'code', 'taxon', 'name'])
               df['percentage'] = df['percentage'].apply(lambda x:float(x.strip('%')) if isinstance(x, str) == True else float(x))
               df = df.sort_values(by = ['percentage'], ascending = False)
               df = df[df['code'].isin(['U', 'S'])]
               df = df.reset_index(drop = True)
               tempdf = pandas.DataFrame()
               d = {}
               t = df['name'].count()
               for i in range((t if t < 3 else 3)):
                    d.update({'#Accession': f"{kraken_a.parts[0]}",
                        f"#{i+1} Match": df.loc[i, 'name'].strip(), f"%{i+1}": df.loc[i, 'percentage']
                        })
               tempdf = pandas.DataFrame(data = d, index = [0])
               if id_table.empty:
                    id_table = tempdf
               else:
                    id_table = id_table.append(tempdf, sort = True)
          cols_list = ['#Accession', '#1 Match', '%1', '#2 Match', '%2', '#3 Match', '%3']
          id_table = id_table.reindex(cols_list, axis = 'columns')
          id_table.to_csv(f"{output}", sep = "\t", index = False)
          subprocess.run("sed -i 's/%[0-9]/%/g' {output}", shell=True)



rule QC_gene_summary:
   input:
        seqdata = "seq_data.tab",
        sp = "species_identification.tab",
        denovo = "denovo.tab",
        mlst = "mlst.tab",
        resist = "resistome.tab",
        vf = "virulome.tab",
        plasmid = "plasmid.tab"
   output:
        qc = "QC_summary.txt",
        gene = "gene_summary.txt"
   run:
# Import pandas library
        import pandas as pd
### Read all intermediate files with '\t' separator
        seqdata = pd.read_csv(f"{input.seqdata}", sep='\t')
        #removing the last empty column generated from extra row in yield tab and writing back to the same df
        seqdata = seqdata.loc[:, ~seqdata.columns.str.contains('^Unnamed')]
        denovo = pd.read_csv(f"{input.denovo}", sep='\t')
        sp = pd.read_csv(f"{input.sp}", sep='\t')
        cols_list = ['#Accession', 'scheme', 'ST', 'allele1', 'allele2', 'allele3', 'allele4', 'allele5', 'allele6', 'allele7', 'allele8']
        mlst = pd.read_csv(f"{input.mlst}", sep='\t', header=None, names=cols_list)
        resist = pd.read_csv(f"{input.resist}", sep='\t')
        vf = pd.read_csv(f"{input.vf}", sep='\t')
        plasmid = pd.read_csv(f"{input.plasmid}", sep='\t')


### Split sample name by removing "filtered_contigs/" and ".fna"
        denovo['Name'] = denovo['Name'].str.replace(r'filtered_contigs/', '')
        denovo['Name'] = denovo['Name'].str.replace(r'.fna', '')
        denovo = denovo.rename({'Name': '#Accession'}, axis=1)
        
        mlst['#Accession'] = mlst['#Accession'].str.replace(r'filtered_contigs/', '')
        mlst['#Accession'] = mlst['#Accession'].str.replace(r'.fna', '')

### Remove strings "/*.tab" from column [0]
        resist['#FILE'] = resist['#FILE'].str.replace(r'/abricate.tab', '')
        vf['#FILE'] = vf['#FILE'].str.replace(r'/vfdb.tab', '')
        plasmid['#FILE'] = plasmid['#FILE'].str.replace(r'/plasmid.tab', '')
#### Rename NUM_FOUND for each gene_files
        resist = resist.rename({'NUM_FOUND': 'NUM_AMR'}, axis=1)
        vf = vf.rename({'NUM_FOUND': 'NUM_VF'}, axis=1)
        plasmid = plasmid.rename({'NUM_FOUND': 'NUM_PLASMID'}, axis=1)

### Creating an array for tsv files
        tsv_files = [denovo, mlst]
# store the result in Output_df dataframe.
# Here common column is '#Accession' column
        Output_df = pd.merge(seqdata, sp, on='#Accession', how='left')

        for i in tsv_files:
            Output_df = pd.merge(Output_df, i, on='#Accession', how='left')

# Merge gene files into Output_df2
        Output_df2 = pd.merge(resist, plasmid, on='#FILE', how='left')
        Output_df2 = pd.merge(Output_df2, vf, on='#FILE', how='left')

# Now store the 'Output_df' in tsv file 'OC_summary.txt'
        Output_df.to_csv(f"{output.qc}", sep="\t", header=True, index=False, na_rep="NA")
        Output_df2.to_csv(f"{output.gene}", sep="\t", header=True, index=False, na_rep="NA")




# rule creating phet_config yaml file by calling shell script containing..
# ..awk one liners filtering and listing good quality bacterial pathogens identified by Kraken2

rule phet_config:
       input:
             QC = "QC_summary.txt"
       output:
             "PHET/phet.yaml"
       shell:
             """
             /phe/tools/PHET/scripts/phet_makefile.sh {input.QC} >> {output}
             """

         


